+++
date = 2022-02-17
title = "数据库背后的数据结构"

[taxonomies]
categories = ["Database"]
tags = ["database"]
+++
### 来设计一个最简单的数据库
可以通过两个bash函数来实现一个简单的KV存储

```bash
#! /bin/bash

db_set() {
  echo "$1,$2" >> database
}

db_get() {
	grep "^$1," database | sed -e "s/^$s1,//" | tail -n 1
}
```
这里我们用两个函数，一个写入，一个读取，底层存储是一个叫`database`的文件来做的，每行保存一个KV对，由逗号分开，每次调用写入都会往文件后面append进去一个新的记录，所以如果你对同一个key做过多次更新，那么旧的记录不会删除，每次都会生成新的记录。读取时候会去查到包含key的那些记录，然后返回最后一条记录，也是最新的记录。

```bash
$ db_set a 'a'
$ db_set b 'b'
$ db_get a
a
$ db_set a 'A'
$ db_get a
A
$ cat database
a,a
b,b
a,A
```
在简单数据情况下这个函数的表现还不错，但是在数据库记录很大的时候就表现的很糟糕了。`db_get` 需要扫描整个数据库问题找到查找的那个key，时间复杂度是`O(n)`

想要高效的从数据库查找特定的key，我们需要一个索引来帮我们快速查询数据。其背后的基本思想就是存储一些元数据，来帮助我们快速的找到查找的数据，如果我们想要通过不同的方式查找相同的数据，那么则需要在数据的不同字段上建立不同的索引。

索引的建立并不会影响存储数据的内容，它只会影响查找的性能。维护额外的索引也会导致额外的开销，例如写入的性能也会受到索引影响，因为每一个写操作都要去更新对应的索引。

### 使用Hash来建立索引
利用hashmap来做一个KV存储是最常见的做法，我们这里稍微有一些不同，重新设计一个简单的数据库 
* 它的存储还是按照之前append的方式增量式写入到一个文件中，存储在磁盘上。
* key和value之间用逗号分割。
* 同时我们要维护一个hashmap，在这个hashmap里，它的key是这个数据的key，value是这个数据记录在存储文件中的字节偏移量。
* 每次append写入新的记录的时候也要去更新这个hashmap
* 查找时候，先在hashmap里找到这个key的偏移量，然后读入存储文件，通过偏移量快速找到对应数据的开始位置。

这个其实就是`Riak`的存储引擎`Bitcask`的基本实现原理
* Bitcask提供了高性能的读写操作
* 数据从硬盘加载只需要一次寻址，效率很高
* 适用于key经常更新的情况，比如记录一个URL被访问的次数，很多的写操作都是在更新同一个key

这里有个问题：数据都存储在一个文件里，而且都是增量式，那么如何避免磁盘空间被占满呢？
有个很好的解决办法就是把数据分成segment来存储
* 数据根据指定的大小，切分成一个一个的segment
* 每个segment存储在一个文件里，每个segment也有自己都应的哈希表
* 当这个文件达到指定的大小之后，则开始写下一个文件。
* 然后对之前的这些segment文件进行压缩，压缩的过程就是把重复的key的记录删掉，只保留最新的值
* 还可以把压缩后的多个文件再合并到一起
* 压缩和合并的操作可以在后台一个独立线程中执行，不影响数据库对外的服务
* 完成之后再对新的segment在内存中生成hashmap
* 读请求这个时候可以切换到新的segment文件上，原始的那些文件可以删除。
* 查询时候先查最新的hashmap，如果没有，则查找次新的，以此类推。
* 压缩和合并的操作会让segment的数量相对非常少，因此这个查找过程也不会查太多的hashmap。
	
实际中还有很多细节来保证这个设计的正常工作
* 文件格式 - CSV并不是记录数据的最合适格式，计算出String的字节长度后存储在二进制文件中会更快也更简单。
* 删除记录 - 如果要删除某个记录，需要写入一个特殊的删除记录，当log文件合并在一起的时候，这个记录会告诉合并的代码来删掉这个key的任何记录
* 数据恢复 - 如果数据库重启了，内存中的哈希表记录就全部都丢了。理论上，可以通过从头到尾读取每个segment的记录来重建哈希表。但是这个可能会花费很长时间。Bitcask是通过从硬盘加载哈希表的快照来恢复的，这样时间更短。
* 不完整数据 - 如果DB崩溃导致一些数据没有写完全，出现部分数据，可以通过checksums来找到这些不完整的数据，然后忽略掉。
* 并发控制 - 只保持一个写线程，数据segment只能append写，而且是不可变的。这样可以支持多线程读取。

同时`Append-only` 被证明是更好的设计， 而不是去修改已有的记录
* 增量式append写入和segment合并的过程都是顺序的写操作，对于磁盘写入来说比随机写入更快，因为不需要频繁的寻址，尤其是在传统的机械式磁盘中。SSD也更喜欢这种顺序写入
* 在append only和数据不变的情况下，并发和崩溃恢复会更简单，不需要考虑当修改一个记录到一半的时候crash掉的情况
* 合并segments可以避免产生更多的数据碎片

但是hashmap作为索引实现也有一些限制
* hashmap都是加载到内存里的，对于非常大的数据，就会占用很多内存。也可以把索引保存在磁盘上，但是性能会大打折扣，因为需要很多随机读取I/O, 同时hash冲突也需要复杂的逻辑来处理。
* 区间查询的性能不够好，例如想要查询所有在`kitty00000`到`kitty99999`的数据，需要在所有的hashmap里查找每一个key
